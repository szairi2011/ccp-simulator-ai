{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\e1079458\\work\\learn-ml\\learn_transformers\\ccp-simulator-ai\\.ccp_simulator_venv\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\e1079458\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\e1079458\\work\\learn-ml\\learn_transformers\\ccp-simulator-ai\\.ccp_simulator_venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tokens for the given input sequence is: 259\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# This cell is only needed when working from local environment, due to local SSL security when loading the HuggingFace model and token below. Remove this when working from Colab or Kaggle for example\n",
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = ''\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the input sequence\n",
    "input_sequence = '''<TrdCaptRpt RptID=\"26981223988\" TrdDt=\"2022-12-21\" BizDt=\"2023-01-20\" TxnTm=\"2023-04-11T22:25:13.545-7:00\" TrdID=\"26981223988\" TransTyp=\"2\" RptTyp=\"0\" LastQty=\"97.0\" LastPx=\"540.698\"><Hdr Snt=\"2023-04-11T23:14:12.436+01:00\" TID=\"MGEX\" SID=\"D210\"/><Instrmt Exch=\"SNTL\" ID=\"W\" MMY=\"202307\" CFI=\"FCCPXX\"/><RptSide Side=\"2\" AvgPxInd=\"0\" AllocInd=\"1\" AllocGrpInst=\"1\"><Pty ID=\"210\" R=\"1\"/></RptSide></TrdCaptRpt>'''\n",
    "\n",
    "# Tokenize the input sequence\n",
    "tokenized_input = tokenizer.encode(input_sequence)\n",
    "\n",
    "# Calculate the number of tokens\n",
    "num_tokens = len(tokenized_input)\n",
    "\n",
    "print(f'The number of tokens for the given input sequence is: {num_tokens}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ccp_simulator_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
